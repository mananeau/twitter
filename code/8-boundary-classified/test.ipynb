{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     141
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# !/usr/bin/env python\n",
    "# coding: utf-8\n",
    "# run using: sbatch --array=0-9 7.9-get-predictions-from-BERT.sh\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# column = sys.argv[1]\n",
    "column = 'is_unemployed'\n",
    "\n",
    "\n",
    "####################################################################################################################################\n",
    "# loading the model\n",
    "####################################################################################################################################\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "from transformers import BertTokenizer\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "from box import Box\n",
    "import pandas as pd\n",
    "import collections\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "# import sys\n",
    "import random\n",
    "import numpy as np\n",
    "# import apex\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import datetime\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from fast_bert.modeling import BertForMultiLabelSequenceClassification\n",
    "from fast_bert.data_cls import BertDataBunch, InputExample, InputFeatures, MultiLabelTextProcessor, \\\n",
    "    convert_examples_to_features\n",
    "from fast_bert.learner_cls import BertLearner\n",
    "# from fast_bert.metrics import accuracy_multilabel, accuracy_thresh, fbeta, roc_auc, accuracy\n",
    "from fast_bert.metrics import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "run_start_time = datetime.datetime.today().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "root_path='/scratch/da2734/twitter/running_on_200Msamples/'\n",
    "\n",
    "\n",
    "def create_model(columnm, epoch):\n",
    "#     if not os.path.exists('/scratch/da2734/twitter/running_on_200Msamples/log_running_on_samples_{}/'.format(column)):\n",
    "#         os.makedirs('/scratch/da2734/twitter/running_on_200Msamples/log_running_on_samples_{}/'.format(column))\n",
    "\n",
    "#     if not os.path.exists('/scratch/da2734/twitter/running_on_200Msamples/output_binary_{}'.format(column)):\n",
    "#         os.makedirs('/scratch/da2734/twitter/running_on_200Msamples/output_binary_{}'.format(column))\n",
    "\n",
    "    LOG_PATH = Path('/scratch/da2734/twitter/running_on_200Msamples/log_running_on_samples/'.format(column))\n",
    "    DATA_PATH = Path('/scratch/da2734/twitter/mturk_mar6/data_binary_class_balanced_UNDERsampled/')\n",
    "    LABEL_PATH = Path('/scratch/da2734/twitter/mturk_mar6/data_binary_class_balanced_UNDERsampled/')\n",
    "    OUTPUT_PATH = Path(\n",
    "        '/scratch/da2734/twitter/running_on_200Msamples/running_on_samples_output_binary_pos_neg_balanced_{}'.format(\n",
    "            column))\n",
    "    FINETUNED_PATH = None\n",
    "\n",
    "    args = Box({\n",
    "        \"run_text\": \"labor mturk ar 6 binary\",\n",
    "        \"train_size\": -1,\n",
    "        \"val_size\": -1,\n",
    "        \"log_path\": LOG_PATH,\n",
    "        \"full_data_dir\": DATA_PATH,\n",
    "        \"data_dir\": DATA_PATH,\n",
    "        \"task_name\": \"labor_market_classification\",\n",
    "        \"no_cuda\": False,\n",
    "        #     \"bert_model\": BERT_PRETRAINED_PATH,\n",
    "        \"output_dir\": OUTPUT_PATH,\n",
    "        \"max_seq_length\": 512,\n",
    "        \"do_train\": True,\n",
    "        \"do_eval\": True,\n",
    "        \"do_lower_case\": True,\n",
    "        \"train_batch_size\": 56,\n",
    "        \"eval_batch_size\": 16,\n",
    "        \"learning_rate\": 5e-5,\n",
    "        \"num_train_epochs\": 100,\n",
    "        \"warmup_proportion\": 0.0,\n",
    "        \"no_cuda\": False,\n",
    "        \"local_rank\": -1,\n",
    "        \"seed\": 42,\n",
    "        \"gradient_accumulation_steps\": 1,\n",
    "        \"optimize_on_cpu\": False,\n",
    "        \"fp16\": False,\n",
    "        \"fp16_opt_level\": \"O1\",\n",
    "        \"weight_decay\": 0.0,\n",
    "        \"adam_epsilon\": 1e-8,\n",
    "        \"max_grad_norm\": 1.0,\n",
    "        \"max_steps\": -1,\n",
    "        \"warmup_steps\": 500,\n",
    "        \"logging_steps\": 50,\n",
    "        \"eval_all_checkpoints\": True,\n",
    "        \"overwrite_output_dir\": True,\n",
    "        \"overwrite_cache\": True,\n",
    "        \"seed\": 42,\n",
    "        \"loss_scale\": 128,\n",
    "        \"task_name\": 'intent',\n",
    "        \"model_name\": 'bert-base-uncased',\n",
    "        \"model_type\": 'bert'\n",
    "    })\n",
    "\n",
    "    import logging\n",
    "\n",
    "    logfile = str(LOG_PATH / 'log-{}-{}.txt'.format(run_start_time, args[\"run_text\"]))\n",
    "\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "        datefmt='%m/%d/%Y %H:%M:%S',\n",
    "        handlers=[\n",
    "            logging.FileHandler(logfile),\n",
    "            logging.StreamHandler(sys.stdout)\n",
    "        ])\n",
    "\n",
    "    logger = logging.getLogger()\n",
    "\n",
    "    logger.info(args)\n",
    "\n",
    "    device = torch.device('cuda')\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        args.multi_gpu = True\n",
    "    else:\n",
    "        args.multi_gpu = False\n",
    "\n",
    "    label_cols = ['class']\n",
    "\n",
    "    databunch = BertDataBunch(\n",
    "        args['data_dir'],\n",
    "        LABEL_PATH,\n",
    "        args.model_name,\n",
    "        train_file='train_{}.csv'.format(column),\n",
    "        val_file='val_{}.csv'.format(column),\n",
    "        label_file='label_{}.csv'.format(column),\n",
    "        # test_data='test.csv',\n",
    "        text_col=\"text\",  # this is the name of the column in the train file that containts the tweet text\n",
    "        label_col=label_cols,\n",
    "        batch_size_per_gpu=args['train_batch_size'],\n",
    "        max_seq_length=args['max_seq_length'],\n",
    "        multi_gpu=args.multi_gpu,\n",
    "        multi_label=False,\n",
    "        model_type=args.model_type)\n",
    "\n",
    "    num_labels = len(databunch.labels)\n",
    "    print('num_labels', num_labels)\n",
    "\n",
    "    print('time taken to load all this stuff:', str(time.time() - start_time), 'seconds')\n",
    "\n",
    "    # metrics defined: https://github.com/kaushaltrivedi/fast-bert/blob/d89e2aa01d948d6d3cdea7ad106bf5792fea7dfa/fast_bert/metrics.py\n",
    "    metrics = []\n",
    "    # metrics.append({'name': 'accuracy_thresh', 'function': accuracy_thresh})\n",
    "    # metrics.append({'name': 'roc_auc', 'function': roc_auc})\n",
    "    # metrics.append({'name': 'fbeta', 'function': fbeta})\n",
    "    metrics.append({'name': 'accuracy', 'function': accuracy})\n",
    "#     metrics.append({'name': 'roc_auc_save_to_plot_binary', 'function': roc_auc_save_to_plot_binary})\n",
    "    # metrics.append({'name': 'accuracy_multilabel', 'function': accuracy_multilabel})\n",
    "\n",
    "    learner = BertLearner.from_pretrained_model(\n",
    "        databunch,\n",
    "        pretrained_path='../mturk_mar6/output_binary_pos_neg_balanced_{}/model_out_{}/'.format(column, epoch),\n",
    "        metrics=metrics,\n",
    "        device=device,\n",
    "        logger=logger,\n",
    "        output_dir=args.output_dir,\n",
    "        finetuned_wgts_path=FINETUNED_PATH,\n",
    "        warmup_steps=args.warmup_steps,\n",
    "        multi_gpu=args.multi_gpu,\n",
    "        is_fp16=args.fp16,\n",
    "        multi_label=False,\n",
    "        logging_steps=0)\n",
    "\n",
    "    return learner\n",
    "\n",
    "\n",
    "best_epochs = {\n",
    "    'is_hired_1mo': 10,\n",
    "    'lost_job_1mo': 9,\n",
    "    'job_offer': 5,\n",
    "    'is_unemployed': 6,\n",
    "    'job_search': 8\n",
    "}\n",
    "\n",
    "start = time.time()\n",
    "learner = create_model(column, best_epochs[column])\n",
    "print('load model:', str(time.time() - start_time), 'seconds')\n",
    "\n",
    "\n",
    "#\n",
    "# def get_env_var(varname, default):\n",
    "#     if os.environ.get(varname) != None:\n",
    "#         var = int(os.environ.get(varname))\n",
    "#         print(varname, ':', var)\n",
    "#     else:\n",
    "#         var = default\n",
    "#         print(varname, ':', var, '(Default)')\n",
    "#     return var\n",
    "\n",
    "\n",
    "# Choose Number of Nodes To Distribute Credentials: e.g. jobarray=0-4, cpu_per_task=20, credentials = 90 (<100)\n",
    "# SLURM_JOB_ID = get_env_var('SLURM_JOB_ID', 0)\n",
    "# SLURM_ARRAY_TASK_ID = get_env_var('SLURM_ARRAY_TASK_ID', 0)\n",
    "# SLURM_ARRAY_TASK_COUNT = get_env_var('SLURM_ARRAY_TASK_COUNT', 1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('SLURM_JOB_ID', SLURM_JOB_ID)\n",
    "print('SLURM_ARRAY_TASK_ID', SLURM_ARRAY_TASK_ID)\n",
    "print('SLURM_ARRAY_TASK_COUNT', SLURM_ARRAY_TASK_COUNT)\n",
    "\n",
    "\n",
    "# ####################################################################################################################################\n",
    "# # loading data\n",
    "# ####################################################################################################################################\n",
    "\n",
    "import time\n",
    "import pyarrow.parquet as pq\n",
    "from glob import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "path_to_data='/scratch/spf248/twitter/data/classification/US/'\n",
    "\n",
    "\n",
    "print('Load Filtered Tweets:')\n",
    "# filtered contains 8G of data!!\n",
    "start_time = time.time()\n",
    "\n",
    "paths_to_filtered=list(np.array_split(\n",
    "                        glob(os.path.join(path_to_data,'filtered','*.parquet')),\n",
    "                        SLURM_ARRAY_TASK_COUNT)[SLURM_ARRAY_TASK_ID]\n",
    "                       )\n",
    "\n",
    "print('number of splits', len(np.array_split(\n",
    "                        glob(os.path.join(path_to_data,'filtered','*.parquet')),\n",
    "                        SLURM_ARRAY_TASK_COUNT)))\n",
    "\n",
    "print('number of files IN split', len(np.array_split(\n",
    "                        glob(os.path.join(path_to_data,'filtered','*.parquet')),\n",
    "                        SLURM_ARRAY_TASK_COUNT)[SLURM_ARRAY_TASK_ID]))\n",
    "\n",
    "print('#files:', len(paths_to_filtered))\n",
    "\n",
    "tweets_filtered=pd.DataFrame()\n",
    "for file in paths_to_filtered:\n",
    "    file = '/scratch/spf248/twitter/data/classification/US/random/part-02175-1c1e6466-49fa-411b-beb0-276d14cdffab-c000.snappy.parquet'\n",
    "    print(file)\n",
    "    tweets_filtered=pd.concat([tweets_filtered,pd.read_parquet(file)[['tweet_id','text']][:100]])\n",
    "    print(tweets_filtered.shape)\n",
    "#     break\n",
    "\n",
    "print('time taken to load keyword filtered sample:', str(time.time() - start_time), 'seconds')\n",
    "print('tweets_filtered.shape', tweets_filtered.shape)\n",
    "\n",
    "\n",
    "print('Predictions of Filtered Tweets:')\n",
    "start_time = time.time()\n",
    "predictions_filtered = learner.predict_batch(tweets_filtered['text'].values.tolist())\n",
    "print('time taken:', str(time.time() - start_time), 'seconds')\n",
    "\n",
    "predictions_filtered = predictions_filtered.set_index(tweets_filtered.tweet_id).rename(columns={\n",
    "        '0':'pos_model',\n",
    "        '1':'neg_model',\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_filtered.set_index(tweets_filtered.tweet_id).rename(columns={\n",
    "        '0':'pos_model',\n",
    "        '1':'neg_model',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = pd.DataFrame(\n",
    "[dict(prediction) for prediction in predictions_filtered],\n",
    "index=tweets_filtered.tweet_id).rename(columns={\n",
    "        '0':'pos_model',\n",
    "        '1':'neg_model',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/22/2020 17:56:48 - INFO - root -   {'run_text': 'labor mturk ar 6 binary', 'train_size': -1, 'val_size': -1, 'log_path': PosixPath('/scratch/da2734/twitter/running_on_200Msamples/log_running_on_samples'), 'full_data_dir': PosixPath('/scratch/da2734/twitter/mturk_mar6/data_binary_class_balanced_UNDERsampled'), 'data_dir': PosixPath('/scratch/da2734/twitter/mturk_mar6/data_binary_class_balanced_UNDERsampled'), 'task_name': 'intent', 'no_cuda': False, 'output_dir': PosixPath('/scratch/da2734/twitter/running_on_200Msamples/running_on_samples_output_binary_pos_neg_balanced_is_unemployed'), 'max_seq_length': 512, 'do_train': True, 'do_eval': True, 'do_lower_case': True, 'train_batch_size': 256, 'eval_batch_size': 16, 'learning_rate': 5e-05, 'num_train_epochs': 100, 'warmup_proportion': 0.0, 'local_rank': -1, 'seed': 42, 'gradient_accumulation_steps': 1, 'optimize_on_cpu': False, 'fp16': False, 'fp16_opt_level': 'O1', 'weight_decay': 0.0, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'max_steps': -1, 'warmup_steps': 500, 'logging_steps': 50, 'eval_all_checkpoints': True, 'overwrite_output_dir': True, 'overwrite_cache': True, 'loss_scale': 128, 'model_name': 'bert-base-uncased', 'model_type': 'bert'}\n",
      "04/22/2020 17:56:48 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/da2734/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "04/22/2020 17:56:48 - INFO - root -   Loading features from cached file /scratch/da2734/twitter/mturk_mar6/data_binary_class_balanced_UNDERsampled/cache/cached_bert_train_multi_class_512_train_is_unemployed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/spf248/pyenv/py3.7/lib/python3.7/site-packages/ipykernel_launcher.py:53: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/22/2020 17:56:48 - INFO - root -   Loading features from cached file /scratch/da2734/twitter/mturk_mar6/data_binary_class_balanced_UNDERsampled/cache/cached_bert_dev_multi_class_512_val_is_unemployed.csv\n",
      "num_labels 2\n",
      "time taken to load all this stuff: 3.317996025085449 seconds\n",
      "04/22/2020 17:56:49 - INFO - transformers.configuration_utils -   loading configuration file ../mturk_mar6/output_binary_pos_neg_balanced_is_unemployed/model_out_6/config.json\n",
      "04/22/2020 17:56:49 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"eos_token_ids\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "04/22/2020 17:56:49 - INFO - transformers.modeling_utils -   loading weights file ../mturk_mar6/output_binary_pos_neg_balanced_is_unemployed/model_out_6/pytorch_model.bin\n",
      "load model: 13.22448444366455 seconds\n",
      "SLURM_JOB_ID 50\n",
      "SLURM_ARRAY_TASK_ID 50\n",
      "SLURM_ARRAY_TASK_COUNT 2000\n",
      "Load Filtered Tweets:\n",
      "number of splits 2000\n",
      "number of files IN split 1\n",
      "#files: 1\n",
      "/scratch/spf248/twitter/data/classification/US/filtered_10perct_sample/part-01609-e5ecb1c7-f08f-4246-a46d-2643ba831074-c000.snappy.parquet\n",
      "(38381, 2)\n",
      "time taken to load keyword filtered sample: 0.14035606384277344 seconds\n",
      "tweets_filtered.shape (38381, 2)\n",
      "Predictions of Filtered Tweets:\n",
      "04/22/2020 17:56:59 - INFO - root -   Writing example 0 of 1000\n",
      "batch size torch.Size([256, 512])\n",
      "52.27197265625 gb free 11441.1875 gb total\n",
      "batch size torch.Size([256, 512])\n",
      "8885.26806640625 gb free 11441.1875 gb total\n",
      "batch size torch.Size([256, 512])\n",
      "8885.26806640625 gb free 11441.1875 gb total\n",
      "batch size torch.Size([232, 512])\n",
      "8885.54931640625 gb free 11441.1875 gb total\n",
      "inference done\n",
      "time taken: 64.20341873168945 seconds\n",
      "time per tweet 0.06420401287078857 sec\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "            1         0\n",
      "0    0.956904  0.043096\n",
      "1    0.960345  0.039655\n",
      "2    0.715390  0.284610\n",
      "3    0.962776  0.037224\n",
      "4    0.913324  0.086676\n",
      "..        ...       ...\n",
      "995  0.949559  0.050441\n",
      "996  0.936581  0.063419\n",
      "997  0.927770  0.072230\n",
      "998  0.874876  0.125124\n",
      "999  0.878714  0.121286\n",
      "\n",
      "[1000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# !/usr/bin/env python\n",
    "# coding: utf-8\n",
    "# run using: sbatch --array=0-9 7.9-get-predictions-from-BERT.sh\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# column = sys.argv[1]\n",
    "column = 'is_unemployed'\n",
    "\n",
    "\n",
    "####################################################################################################################################\n",
    "# loading the model\n",
    "####################################################################################################################################\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "from transformers import BertTokenizer\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "from box import Box\n",
    "import pandas as pd\n",
    "import collections\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "# import sys\n",
    "import random\n",
    "import numpy as np\n",
    "# import apex\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import datetime\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from fast_bert.modeling import BertForMultiLabelSequenceClassification\n",
    "from fast_bert.data_cls import BertDataBunch, InputExample, InputFeatures, MultiLabelTextProcessor, \\\n",
    "    convert_examples_to_features\n",
    "from fast_bert.learner_cls import BertLearner\n",
    "# from fast_bert.metrics import accuracy_multilabel, accuracy_thresh, fbeta, roc_auc, accuracy\n",
    "from fast_bert.metrics import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "run_start_time = datetime.datetime.today().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "root_path='/scratch/da2734/twitter/running_on_200Msamples/'\n",
    "\n",
    "\n",
    "def create_model(columnm, epoch):\n",
    "#     if not os.path.exists('/scratch/da2734/twitter/running_on_200Msamples/log_running_on_samples_{}/'.format(column)):\n",
    "#         os.makedirs('/scratch/da2734/twitter/running_on_200Msamples/log_running_on_samples_{}/'.format(column))\n",
    "\n",
    "#     if not os.path.exists('/scratch/da2734/twitter/running_on_200Msamples/output_binary_{}'.format(column)):\n",
    "#         os.makedirs('/scratch/da2734/twitter/running_on_200Msamples/output_binary_{}'.format(column))\n",
    "\n",
    "    LOG_PATH = Path('/scratch/da2734/twitter/running_on_200Msamples/log_running_on_samples/'.format(column))\n",
    "    DATA_PATH = Path('/scratch/da2734/twitter/mturk_mar6/data_binary_class_balanced_UNDERsampled/')\n",
    "    LABEL_PATH = Path('/scratch/da2734/twitter/mturk_mar6/data_binary_class_balanced_UNDERsampled/')\n",
    "    OUTPUT_PATH = Path(\n",
    "        '/scratch/da2734/twitter/running_on_200Msamples/running_on_samples_output_binary_pos_neg_balanced_{}'.format(\n",
    "            column))\n",
    "    FINETUNED_PATH = None\n",
    "\n",
    "    args = Box({\n",
    "        \"run_text\": \"labor mturk ar 6 binary\",\n",
    "        \"train_size\": -1,\n",
    "        \"val_size\": -1,\n",
    "        \"log_path\": LOG_PATH,\n",
    "        \"full_data_dir\": DATA_PATH,\n",
    "        \"data_dir\": DATA_PATH,\n",
    "        \"task_name\": \"labor_market_classification\",\n",
    "        \"no_cuda\": False,\n",
    "        #     \"bert_model\": BERT_PRETRAINED_PATH,\n",
    "        \"output_dir\": OUTPUT_PATH,\n",
    "        \"max_seq_length\": 512,\n",
    "        \"do_train\": True,\n",
    "        \"do_eval\": True,\n",
    "        \"do_lower_case\": True,\n",
    "        \"train_batch_size\": 256,\n",
    "        \"eval_batch_size\": 16,\n",
    "        \"learning_rate\": 5e-5,\n",
    "        \"num_train_epochs\": 100,\n",
    "        \"warmup_proportion\": 0.0,\n",
    "        \"no_cuda\": False,\n",
    "        \"local_rank\": -1,\n",
    "        \"seed\": 42,\n",
    "        \"gradient_accumulation_steps\": 1,\n",
    "        \"optimize_on_cpu\": False,\n",
    "        \"fp16\": False,\n",
    "        \"fp16_opt_level\": \"O1\",\n",
    "        \"weight_decay\": 0.0,\n",
    "        \"adam_epsilon\": 1e-8,\n",
    "        \"max_grad_norm\": 1.0,\n",
    "        \"max_steps\": -1,\n",
    "        \"warmup_steps\": 500,\n",
    "        \"logging_steps\": 50,\n",
    "        \"eval_all_checkpoints\": True,\n",
    "        \"overwrite_output_dir\": True,\n",
    "        \"overwrite_cache\": True,\n",
    "        \"seed\": 42,\n",
    "        \"loss_scale\": 128,\n",
    "        \"task_name\": 'intent',\n",
    "        \"model_name\": 'bert-base-uncased',\n",
    "        \"model_type\": 'bert'\n",
    "    })\n",
    "\n",
    "    import logging\n",
    "\n",
    "    logfile = str(LOG_PATH / 'log-{}-{}.txt'.format(run_start_time, args[\"run_text\"]))\n",
    "\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "        datefmt='%m/%d/%Y %H:%M:%S',\n",
    "        handlers=[\n",
    "            logging.FileHandler(logfile),\n",
    "            logging.StreamHandler(sys.stdout)\n",
    "        ])\n",
    "\n",
    "    logger = logging.getLogger()\n",
    "\n",
    "    logger.info(args)\n",
    "\n",
    "    device = torch.device('cuda')\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        args.multi_gpu = True\n",
    "    else:\n",
    "        args.multi_gpu = False\n",
    "\n",
    "    label_cols = ['class']\n",
    "\n",
    "    databunch = BertDataBunch(\n",
    "        args['data_dir'],\n",
    "        LABEL_PATH,\n",
    "        args.model_name,\n",
    "        train_file='train_{}.csv'.format(column),\n",
    "        val_file='val_{}.csv'.format(column),\n",
    "        label_file='label_{}.csv'.format(column),\n",
    "        # test_data='test.csv',\n",
    "        text_col=\"text\",  # this is the name of the column in the train file that containts the tweet text\n",
    "        label_col=label_cols,\n",
    "        batch_size_per_gpu=args['train_batch_size'],\n",
    "        max_seq_length=args['max_seq_length'],\n",
    "        multi_gpu=args.multi_gpu,\n",
    "        multi_label=False,\n",
    "        model_type=args.model_type)\n",
    "\n",
    "    num_labels = len(databunch.labels)\n",
    "    print('num_labels', num_labels)\n",
    "\n",
    "    print('time taken to load all this stuff:', str(time.time() - start_time), 'seconds')\n",
    "\n",
    "    # metrics defined: https://github.com/kaushaltrivedi/fast-bert/blob/d89e2aa01d948d6d3cdea7ad106bf5792fea7dfa/fast_bert/metrics.py\n",
    "    metrics = []\n",
    "    # metrics.append({'name': 'accuracy_thresh', 'function': accuracy_thresh})\n",
    "    # metrics.append({'name': 'roc_auc', 'function': roc_auc})\n",
    "    # metrics.append({'name': 'fbeta', 'function': fbeta})\n",
    "    metrics.append({'name': 'accuracy', 'function': accuracy})\n",
    "#     metrics.append({'name': 'roc_auc_save_to_plot_binary', 'function': roc_auc_save_to_plot_binary})\n",
    "    # metrics.append({'name': 'accuracy_multilabel', 'function': accuracy_multilabel})\n",
    "\n",
    "    learner = BertLearner.from_pretrained_model(\n",
    "        databunch,\n",
    "        pretrained_path='../mturk_mar6/output_binary_pos_neg_balanced_{}/model_out_{}/'.format(column, epoch),\n",
    "        metrics=metrics,\n",
    "        device=device,\n",
    "        logger=logger,\n",
    "        output_dir=args.output_dir,\n",
    "        finetuned_wgts_path=FINETUNED_PATH,\n",
    "        warmup_steps=args.warmup_steps,\n",
    "        multi_gpu=args.multi_gpu,\n",
    "        is_fp16=args.fp16,\n",
    "        multi_label=False,\n",
    "        logging_steps=0)\n",
    "\n",
    "    return learner\n",
    "\n",
    "\n",
    "best_epochs = {\n",
    "    'is_hired_1mo': 10,\n",
    "    'lost_job_1mo': 9,\n",
    "    'job_offer': 5,\n",
    "    'is_unemployed': 6,\n",
    "    'job_search': 8\n",
    "}\n",
    "\n",
    "start = time.time()\n",
    "learner = create_model(column, best_epochs[column])\n",
    "print('load model:', str(time.time() - start_time), 'seconds')\n",
    "\n",
    "\n",
    "#\n",
    "# def get_env_var(varname, default):\n",
    "#     if os.environ.get(varname) != None:\n",
    "#         var = int(os.environ.get(varname))\n",
    "#         print(varname, ':', var)\n",
    "#     else:\n",
    "#         var = default\n",
    "#         print(varname, ':', var, '(Default)')\n",
    "#     return var\n",
    "\n",
    "\n",
    "# Choose Number of Nodes To Distribute Credentials: e.g. jobarray=0-4, cpu_per_task=20, credentials = 90 (<100)\n",
    "# SLURM_JOB_ID = get_env_var('SLURM_JOB_ID', 0)\n",
    "# SLURM_ARRAY_TASK_ID = get_env_var('SLURM_ARRAY_TASK_ID', 0)\n",
    "# SLURM_ARRAY_TASK_COUNT = get_env_var('SLURM_ARRAY_TASK_COUNT', 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "SLURM_JOB_ID = 50\n",
    "SLURM_ARRAY_TASK_ID = 50\n",
    "SLURM_ARRAY_TASK_COUNT = 500\n",
    "\n",
    "\n",
    "print('SLURM_JOB_ID', SLURM_JOB_ID)\n",
    "print('SLURM_ARRAY_TASK_ID', SLURM_ARRAY_TASK_ID)\n",
    "print('SLURM_ARRAY_TASK_COUNT', SLURM_ARRAY_TASK_COUNT)\n",
    "\n",
    "\n",
    "# ####################################################################################################################################\n",
    "# # loading data\n",
    "# ####################################################################################################################################\n",
    "\n",
    "import time\n",
    "import pyarrow.parquet as pq\n",
    "from glob import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "path_to_data='/scratch/spf248/twitter/data/classification/US/'\n",
    "\n",
    "\n",
    "print('Load Filtered Tweets:')\n",
    "# filtered contains 8G of data!!\n",
    "start_time = time.time()\n",
    "\n",
    "paths_to_filtered=list(np.array_split(\n",
    "                        glob(os.path.join(path_to_data,'filtered_10perct_sample','*.parquet')),\n",
    "                        SLURM_ARRAY_TASK_COUNT)[SLURM_ARRAY_TASK_ID]\n",
    "                       )\n",
    "\n",
    "print('number of splits', len(np.array_split(\n",
    "                        glob(os.path.join(path_to_data,'filtered_10perct_sample','*.parquet')),\n",
    "                        SLURM_ARRAY_TASK_COUNT)))\n",
    "\n",
    "print('number of files IN split', len(np.array_split(\n",
    "                        glob(os.path.join(path_to_data,'filtered_10perct_sample','*.parquet')),\n",
    "                        SLURM_ARRAY_TASK_COUNT)[SLURM_ARRAY_TASK_ID]))\n",
    "\n",
    "print('#files:', len(paths_to_filtered))\n",
    "\n",
    "tweets_filtered=pd.DataFrame()\n",
    "for file in paths_to_filtered:\n",
    "#     file = '/scratch/spf248/twitter/data/classification/US/random/part-02175-1c1e6466-49fa-411b-beb0-276d14cdffab-c000.snappy.parquet'\n",
    "    print(file)\n",
    "    tweets_filtered=pd.concat([tweets_filtered,pd.read_parquet(file)[['tweet_id','text']]])\n",
    "    print(tweets_filtered.shape)\n",
    "#     break\n",
    "\n",
    "print('time taken to load keyword filtered sample:', str(time.time() - start_time), 'seconds')\n",
    "print('tweets_filtered.shape', tweets_filtered.shape)\n",
    "\n",
    "\n",
    "print('Predictions of Filtered Tweets:')\n",
    "start_time = time.time()\n",
    "tweets_filtered = tweets_filtered[:1000]\n",
    "predictions_filtered = learner.predict_batch(tweets_filtered[:2000]['text'].values.tolist())\n",
    "print('time taken:', str(time.time() - start_time), 'seconds')\n",
    "print('time per tweet', (time.time() - start_time)/tweets_filtered.shape[0], 'sec')\n",
    "\n",
    "print(type(predictions_filtered))\n",
    "print(predictions_filtered)\n",
    "\n",
    "predictions_filtered = predictions_filtered.set_index(tweets_filtered.tweet_id).rename(columns={\n",
    "        '0':'pos_model',\n",
    "        '1':'neg_model',\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time taken to load keyword filtered sample: 0.1307830810546875 seconds\n",
    "tweets_filtered.shape (37408, 2)\n",
    "Predictions of Filtered Tweets:\n",
    "04/22/2020 17:38:13 - INFO - root -   Writing example 0 of 1000\n",
    "batch size torch.Size([256, 512])\n",
    "52.27197265625 gb free 11441.1875 gb total\n",
    "batch size torch.Size([256, 512])\n",
    "8885.26806640625 gb free 11441.1875 gb total\n",
    "batch size torch.Size([256, 512])\n",
    "8885.26806640625 gb free 11441.1875 gb total\n",
    "batch size torch.Size([232, 512])\n",
    "8885.54931640625 gb free 11441.1875 gb total\n",
    "inference done\n",
    "time taken: 64.07160210609436 seconds\n",
    "time per tweet 0.064072172164917 sec\n",
    "<class 'numpy.ndarray'>\n",
    "[[0.7694456  0.2305544 ]\n",
    " [0.87796265 0.12203733]\n",
    " [0.96256316 0.03743681]\n",
    " ...\n",
    " [0.9259158  0.07408419]\n",
    " [0.9504169  0.04958301]\n",
    " [0.83648944 0.16351053]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9338.26806640625 11441.1875\n"
     ]
    }
   ],
   "source": [
    "import torch.cuda as cutorch\n",
    "device = torch.device('cuda')\n",
    "cutorch.get_device_properties(device).total_memory\n",
    "cutorch.memory_stats(device)\n",
    "\n",
    "t = torch.cuda.get_device_properties(0).total_memory\n",
    "c = torch.cuda.memory_cached(0)\n",
    "a = torch.cuda.memory_allocated(0)\n",
    "f = c-a  # free inside cache\n",
    "print(f/1024/1024, t/1024/1024)\n",
    "\n",
    "# for i in range(cutorch.device_count()):\n",
    "#      if cutorch.getMemoryUsage(i) > MEM: \n",
    "#          opts.gpuID = i\n",
    "#          break\n",
    "            \n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
